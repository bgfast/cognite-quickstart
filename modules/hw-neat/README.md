# Neat Basic Data Model

This module contains a basic data model generated using the neat library, along with comprehensive testing tools for validation and development.

## Purpose

The Neat Basic Data Model module provides:
- **Basic data model structure** generated with neat
- **Simple containers and views** for common data types
- **Foundation for data modeling** using neat best practices
- **Comprehensive testing suite** for validation and development

## Structure

### Data Models
- `hw-neat.space.yaml` - Main space for the data model
- `containers/` - Container definitions (generated by neat)
  - `BasicAsset.container.yaml` - Basic asset container with name, description, and type
- `views/` - View definitions (generated by neat)
  - `BasicAsset.view.yaml` - Basic asset view for data access

### Data Sets
- `hw-neat-dataset.DataSet.yaml` - Dataset for data governance

### Testing Tools
- `test_neat_data_model.py` - Comprehensive data model testing script
- `sample_data_generator.py` - Sample data generator for testing
- `neat_integration_test.py` - End-to-end integration testing with Cognite Toolkit

### NEAT Generation Tools
- `generate_edm_yaml_files.py` - Generate YAML files from NeatBasic.xlsx using NEAT (MANUALLY MAINTAINED)
- `NeatBasic.xlsx` - Excel file containing the NEAT data model definition (MANUALLY MAINTAINED - SOURCE OF TRUTH)

### Configuration
- `config.hw-neat.yaml` - Configuration file for deploying the NEAT Basic module (MANUALLY MAINTAINED)

## üìù File Management: Generated vs Manually Maintained

### MANUALLY MAINTAINED FILES (Edit These)
These files should be edited and version controlled:
- `NeatBasic.xlsx` - **Source of truth** for the data model
- `generate_edm_yaml_files.py` - YAML generation script
- `test_neat_data_model.py` - Test suite
- `sample_data_generator.py` - Sample data generator
- `neat_integration_test.py` - Integration tests
- `streamlit/` directory - All Streamlit application files
- `module.toml` - Module metadata
- `README.md` - Module documentation
- `data_sets/*.DataSet.yaml` - Dataset definitions

### GENERATED BY NEAT (Do Not Edit Directly)
These files are automatically generated from `NeatBasic.xlsx`:
- `data_models/containers/*.container.yaml` - Container definitions
- `data_models/views/*.view.yaml` - View definitions
- `data_models/*.space.yaml` - Space definitions
- `data_models/*.datamodel.yaml` - Data model definitions

**‚ö†Ô∏è IMPORTANT**: 
- Never edit generated YAML files directly - your changes will be overwritten
- Always modify `NeatBasic.xlsx` and run `python generate_edm_yaml_files.py` to regenerate
- The Excel file is the single source of truth for the data model

## Usage

### Generating YAML Files from Excel

If you need to regenerate the YAML files from the `NeatBasic.xlsx` file:

```bash
cd modules/hw-neat

# Ensure environment is set up
source ../../cdfenv.sh
cdfenv bgfast  # or your environment name

# Generate YAML files from Excel
python generate_edm_yaml_files.py
```

This will:
- üìä Process the `NeatBasic.xlsx` file using NEAT
- üîç Inspect for any data model issues
- üìù Generate CDF Toolkit-compatible YAML files
- üìã List all generated files
- üß™ Optionally run integration tests

### Basic Deployment

This module should be deployed after the foundation module to provide basic data modeling capabilities.

```bash
# Build and deploy using Cognite Toolkit with hw-neat config
cdf-tk build --env hw-neat
cdf-tk deploy --env hw-neat --dry-run  # Test first
cdf-tk deploy --env hw-neat            # Deploy for real

# Or use the weather config if you prefer
cdf-tk build --env weather
cdf-tk deploy --env weather --dry-run
cdf-tk deploy --env weather
```

### Testing Your NEAT Data Model

#### 1. Comprehensive Data Model Testing

Test your deployed data model with full validation:

```bash
cd modules/hw-neat
python test_neat_data_model.py
```

This will test:
- ‚úÖ Space deployment and configuration
- ‚úÖ Container deployment with correct properties
- ‚úÖ View deployment and accessibility
- ‚úÖ Instance creation and validation
- ‚úÖ Data querying capabilities
- ‚úÖ Data validation constraints

#### 2. Sample Data Generation

Generate realistic test data for your BasicAsset model:

```bash
cd modules/hw-neat
python sample_data_generator.py
```

Features:
- üè≠ Generate realistic asset instances (pumps, compressors, generators, etc.)
- üîç Dry-run mode to preview data before creation
- üìã List existing assets in your data model
- üßπ Cleanup utilities for test data

#### 3. End-to-End Integration Testing

Run complete workflow testing from build to data operations:

```bash
cd modules/hw-neat
python neat_integration_test.py
```

This provides:
- üîç Prerequisites validation
- üèóÔ∏è Automated toolkit build
- üöÄ Deployment testing (dry-run and real)
- üß™ Data model validation
- üè≠ Sample data operations
- üìä Comprehensive reporting

### Interactive Testing Menus

All testing scripts provide interactive menus for easy testing:

```
Select test to run:
1. Prerequisites check only
2. Build and dry-run deploy only
3. Full integration test (no real deploy)
4. Full integration test (with real deploy)
5. NEAT tests only
6. Sample data operations only
7. Exit
```

## BasicAsset Data Model

The BasicAsset model includes:

### Properties
- **name** (required): Asset name
- **description** (optional): Asset description  
- **type** (optional): Asset type/category

### Example Usage

```python
from cognite.client import CogniteClient
from cognite.client.data_classes import NodeApply

# Create a BasicAsset instance
asset = NodeApply(
    space="hw-neat",
    external_id="my_pump_001",
    sources=[{
        "source": {
            "space": "hw-neat",
            "externalId": "BasicAsset",
            "version": "1"
        },
        "properties": {
            "name": "Main Water Pump",
            "description": "Primary water circulation pump",
            "type": "pump"
        }
    }]
)

# Apply to CDF
client = CogniteClient.default_oauth_interactive(project="your-project")
result = client.data_modeling.instances.apply(nodes=[asset])
```

## Dependencies

- CDF project with data modeling capabilities enabled
- Foundation module (for basic setup)
- Python packages: `cognite-sdk`, `cognite-toolkit`, `cognite-neat` (for YAML generation)
- Configuration: `config.hw-neat.yaml` (provided in project root)

## Environment Setup

Ensure your environment is configured:

```bash
# Set up CDF environment
source cdfenv.sh
cdfenv bgfast  # or your environment name

# Verify setup
echo $CDF_PROJECT
echo $CDF_CLUSTER
```

## Configuration File

The `config.hw-neat.yaml` file provides:

- **Module Selection**: Automatically includes foundation and hw-neat modules
- **NEAT-specific Variables**: Space names, container IDs, dataset names
- **Testing Configuration**: Test asset prefixes, sample counts, cleanup settings
- **Environment Variables**: CDF project, cluster, and authentication settings

### Using the Config File

```bash
# Deploy using the hw-neat configuration
cdf-tk build --env hw-neat
cdf-tk deploy --env hw-neat --dry-run
cdf-tk deploy --env hw-neat

# The config automatically includes:
# - modules/common/foundation (basic setup)
# - modules/hw-neat (your NEAT data model)
```

## Neat Integration

The data model files in this module are generated using the neat library:
- **Excel Source**: `NeatBasic.xlsx` contains the data model definition
- **YAML Generation**: `generate_edm_yaml_files.py` processes Excel into toolkit YAML
- **Containers**: Define the data structure and validation rules
- **Views**: Provide the interface for data access and querying
- **Best Practices**: Generated following NEAT and CDF Toolkit conventions

## Testing Best Practices

1. **Always test with dry-run first** - Use dry-run modes to validate before making changes
2. **Use sample data for development** - Generate realistic test data for development and testing
3. **Run integration tests** - Validate the complete workflow from deployment to data operations
4. **Clean up test data** - Use cleanup utilities to maintain a clean testing environment
5. **Monitor test results** - Review generated test reports for detailed analysis

## Troubleshooting

### Common Issues

1. **CDF_PROJECT not set**: Run `source cdfenv.sh && cdfenv <your-env>`
2. **Permission errors**: Ensure your CDF user has data modeling permissions
3. **Module not found**: Ensure you're in the correct directory and dependencies are installed
4. **Deployment failures**: Check prerequisites and run dry-run deploy first

### Getting Help

- Check test reports generated in JSON format for detailed error information
- Use verbose mode in testing scripts for detailed logging
- Review CDF logs for deployment-related issues
